{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unit 3 - Modeling\n",
    "\n",
    "\n",
    "In this notebook we will cover:\n",
    "   1. How to choose a machine learning model?\n",
    "       1. What to choose from?\n",
    "       2. What to test for?\n",
    "       \n",
    "\n",
    "\n",
    "<img src=\"images/MLvisual2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "- Many different algorithms to chose from\n",
    "- First 3 factors to consider when chosing an algorithm:\n",
    "    - Task (Classification, Regression, Clustering, DR)\n",
    "    - Type of data (Labeled, unlabeled)\n",
    "    - Amount of data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/scikit_roadmap.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import spearmanr\n",
    "%matplotlib inline\n",
    "\n",
    "#!pip install numerapi\n",
    "from pathlib import Path\n",
    "import dask.dataframe as dd\n",
    "from dask.array import from_array\n",
    "import numerapi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import (\n",
    "    feature_extraction, feature_selection, decomposition, linear_model,\n",
    "    model_selection, metrics, svm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "napi = numerapi.NumerAPI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create instance of NumerAPI\n",
    "\n",
    "#Use numerAPI to download a single file\n",
    "train_pq_path = \"numerai_training_data_int8.parquet\"\n",
    "val_pq_path = \"numerai_validation_data_int8.parquet\"\n",
    "\n",
    "\n",
    "napi.download_dataset(\"numerai_training_data_int8.parquet\", train_pq_path)\n",
    "napi.download_dataset(\"numerai_validation_data_int8.parquet\", val_pq_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read parquet files into DataFrames\n",
    "df_train = dd.read_parquet('numerai_training_data_int8.parquet')  \n",
    "df_val = dd.read_parquet('numerai_validation_data_int8.parquet') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in df_train if c.startswith(\"feature\")]\n",
    "features_erano = features + [\"erano\"]\n",
    "\n",
    "targets = [c for c in df_train if c.startswith(\"target\")]\n",
    "\n",
    "df_train[\"erano\"] = df_train.era.astype(int)\n",
    "eras = df_train.erano\n",
    "target = \"target\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val[\"erano\"] = df_val.era.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create variables with just feature or target data\n",
    "X_train = df_train.reset_index()[features].to_dask_array(lengths=True)\n",
    "\n",
    "X_train_erano = df_train.reset_index()[features_erano].to_dask_array(lengths=True)\n",
    "\n",
    "y_train = df_train.reset_index()[\"target\"].to_dask_array(lengths=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation\n",
    "\n",
    "- K-fold cross-validation is a statistical method used to estimate the skill of machine learning models.\n",
    "- Provides train/test indices to split data in train/test sets. Split dataset into k consecutive folds (without shuffling by default)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/kfold.png\" width=600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group ðŸ‡°-Fold Cross Validation\n",
    "\n",
    "- Group K-fold is a K-fold iterator variant with non-overlapping groups.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/groupkfold.png\" width=750/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Era-wise Time-series Cross Validation\n",
    "\n",
    "- Prevents you from using any future information to predict out of sample, since your out of sample test set is always in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/tseriessplit.png\" width=750/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn import model_selection, metrics \n",
    "import csv\n",
    "\n",
    "class TimeSeriesSplitGroups(_BaseKFold):\n",
    "    def __init__(self, n_splits=5):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        n_folds = n_splits + 1\n",
    "        group_list = np.unique(groups)\n",
    "        n_groups = len(group_list)\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds ={0} greater\"\n",
    "                 \" than the number of samples: {1}.\").format(n_folds,\n",
    "                                                             n_groups))\n",
    "        indices = np.arange(n_samples)\n",
    "        test_size = (n_groups // n_folds)\n",
    "        test_starts = range(test_size + n_groups % n_folds,\n",
    "                            n_groups, test_size)\n",
    "        #test_starts = list(test_starts)[::-1]\n",
    "        for test_start in test_starts:\n",
    "            \n",
    "            yield (indices[groups.isin(group_list[:test_start])],\n",
    "                   indices[groups.isin(group_list[test_start:test_start + test_size])])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function ðŸ“‰\n",
    "- We will be using a correlation based loss function\n",
    "- MSE looks worse than correlation out of sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The models should be scored based on the rank-correlation (spearman) with the target\n",
    "def numerai_score(y_true, y_pred, eras):\n",
    "    rank_pred = y_pred.groupby(eras).apply(lambda x: x.rank(pct=True, method=\"first\"))\n",
    "    return np.corrcoef(y_true, rank_pred)[0,1]\n",
    "\n",
    "# It can also be convenient while working to evaluate based on the regular (pearson) correlation\n",
    "def correlation_score(y_true, y_pred):\n",
    "    return numpy.corrcoef(y_true, y_pred)[0,1]\n",
    "\n",
    "def spearman(y_true, y_pred): \n",
    "    return spearmanr(y_pred, y_true).correlation \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Thank You and Good Luck!\n",
    "- Like & Subscribe for more!\n",
    "- [Github](https://github.com/peterling7710/NumeraiStarterPack) with the notebooks for this series\n",
    "- Find my socials [here](https://linktr.ee/peterling) for more numer.ai related content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<img src=\"images/TAF.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.35px",
    "left": "1016px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
